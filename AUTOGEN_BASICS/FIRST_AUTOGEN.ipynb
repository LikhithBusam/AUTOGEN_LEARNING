{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05673d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import StructuredMessage\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf88bd",
   "metadata": {},
   "source": [
    "### USING GOOGLE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "612b4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen is a programming framework for building multi-agent applications.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "# Example tool\n",
    "async def web_search(query: str) -> str:\n",
    "    \"\"\"Find information on the web\"\"\"\n",
    "    return \"AutoGen is a programming framework for building multi-agent applications.\"\n",
    "\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gemini-2.0-flash\",  # ✅ supports tool use\n",
    "        api_key=\"AIzaSyC75gcuuklMxi8RyCWa_Ss5waRevWtKtEk\",\n",
    "        model_info=ModelInfo(\n",
    "            vision=False,\n",
    "            function_calling=True,\n",
    "            json_output=True,\n",
    "            family=\"gemini\",\n",
    "            structured_output=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "agent = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        model_client=model_client,\n",
    "        tools=[web_search],\n",
    "        system_message=\"Use tools to solve tasks.\",\n",
    "    )\n",
    "\n",
    "result = await agent.run(task=\"Find information on AutoGen\")\n",
    "\n",
    "# Extract only assistant messages\n",
    "assistant_msgs = [\n",
    "    msg.content for msg in result.messages if msg.source == \"assistant\"\n",
    "]\n",
    "\n",
    "# Print the final assistant response (last one)\n",
    "if assistant_msgs:\n",
    "    print(assistant_msgs[-1])\n",
    "else:\n",
    "    print(\"No assistant output.\")\n",
    "\n",
    "\n",
    "await model_client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e67d9",
   "metadata": {},
   "source": [
    "### OPEN ROUTER MODEL WITH FREE API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e637ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen is a framework designed for developing Large Language Model (LLM)-powered autonomous agents. It leverages the capabilities of LLMs to enable agents to perform various tasks autonomously. The framework emphasizes the compositionality of tasks, allowing users to combine multiple LLMs to solve complex problems. Some key features and aspects of AutoGen include:\n",
      "\n",
      "1. **Autonomous Agents**: AutoGen focuses on creating agents that can operate independently, using LLMs to understand and execute tasks without extensive human intervention.\n",
      "\n",
      "2. **Compositionality**: The framework supports the combination of multiple LLMs to tackle more complicated and multifaceted tasks. This modular approach allows for greater flexibility and scalability.\n",
      "\n",
      "3. **Versatility**: AutoGen can be applied to a wide range of applications, from automating customer support to enhancing creative content generation. It can also be used in fields like data analysis, software development, and more.\n",
      "\n",
      "4. **Efficiency**: By leveraging existing LLMs, AutoGen can reduce the need for extensive datasets and training times, making it a cost-effective solution for developing autonomous agents.\n",
      "\n",
      "5. **Research and Development**: The framework is particularly relevant in research settings, where it can be used to explore new methods and techniques for utilizing LLMs in autonomous tasks.\n",
      "\n",
      "To get started with AutoGen, developers can use the official documentation, tutorials, and examples provided by the framework’s creators. These resources typically include code snippets, step-by-step guides, and best practices for integrating AutoGen into various projects.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "# Example tool\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "async def web_search(query: str) -> str:\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r[\"body\"] for r in ddgs.text(query, max_results=3)]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/mistral-small-3.1-24b-instruct:free\",  # ✅ supports tool use\n",
    "    api_key=\"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\",\n",
    "    model_info=ModelInfo(\n",
    "        vision=False,\n",
    "        function_calling=True,   # ✅ tool use supported\n",
    "        json_output=True,\n",
    "        family=\"mistral\",\n",
    "        structured_output=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "agent = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        model_client=model_client,\n",
    "        tools=[web_search],\n",
    "        system_message=\"Use tools to solve tasks.\",\n",
    "    )\n",
    "\n",
    "result = await agent.run(task=\"Find information on AutoGen\")\n",
    "\n",
    "# Extract only assistant messages\n",
    "assistant_msgs = [\n",
    "    msg.content for msg in result.messages if msg.source == \"assistant\"\n",
    "]\n",
    "\n",
    "# Print the final assistant response (last one)\n",
    "if assistant_msgs:\n",
    "    print(assistant_msgs[-1])\n",
    "else:\n",
    "    print(\"No assistant output.\")\n",
    "\n",
    "\n",
    "await model_client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c77bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
